{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import copy\n",
    "from abc import ABC, abstractmethod\n",
    "import math\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import PIL\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import threshold_otsu\n",
    "import torchvision\n",
    "import torchvision.models as torchmodels\n",
    "import torch.nn.functional as F\n",
    "import openslide\n",
    "import torch.utils.data\n",
    "\n",
    "list_pathstoadd = [\"../../\"]\n",
    "for path in list_pathstoadd:\n",
    "    if(path not in sys.path):\n",
    "        sys.path.append(path)\n",
    "import pydmed\n",
    "from pydmed.utils.data import *\n",
    "import pydmed.lightdl\n",
    "from pydmed.lightdl import *\n",
    "import pydmed.extensions.wsi\n",
    "import pydmed.streamcollector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#settings ====\n",
    "kernel_size = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the model ====\n",
    "module_resnet = torchvision.models.resnet18(pretrained=True)\n",
    "list_modules = list(module_resnet.children())[0:-2]\n",
    "model = torch.nn.Sequential(*list_modules)\n",
    "\n",
    "def func_setpaddingmodes_for_conv2dlayers(module_input, str_paddingmode):\n",
    "    '''\n",
    "    Sets the padding mode of all conv2d modules, either on imediate children or non-imediate children.\n",
    "    '''\n",
    "    #get num_children\n",
    "    num_children = 0\n",
    "    for child in module_input.children():\n",
    "        num_children += 1\n",
    "    \n",
    "    #base case, the module has no children ====\n",
    "    if(num_children == 0):\n",
    "        if(isinstance(module_input, torch.nn.Conv2d)):\n",
    "            module_input.padding_mode = str_paddingmode\n",
    "        return module_input\n",
    "        \n",
    "    #non-base case, loop over children ====\n",
    "    for child in module_input.children():\n",
    "        func_setpaddingmodes_for_conv2dlayers(child, str_paddingmode)\n",
    "    return module_input\n",
    "\n",
    "model = func_setpaddingmodes_for_conv2dlayers(model, \"reflect\") #set paddingmode to \"reflect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dataset ===================\n",
    "rootdir = \"../../NonGit/Data/Sample3Heatmap/\"\n",
    "list_relativedirs = [\"1.tif\", \"2.tif\", \"3.tif\", \"4.tif\", \"5.tif\",\\\n",
    "                     \"6.tif\", \"7.tif\", \"8.tif\", \"9.tif\", \"10.tif\"]\n",
    "list_relativedirs.sort()\n",
    "#make a list of patients\n",
    "list_patients = []\n",
    "for fname in list_relativedirs:\n",
    "    new_patient = Patient(\\\n",
    "            int_uniqueid = list_relativedirs.index(fname),\n",
    "            dict_records = {\n",
    "                \"H&E\":Record(rootdir, fname, {\"resolution\":\"40x\"}),\n",
    "                \"somelabel\": np.random.randint(0,4)\n",
    "             }\n",
    "         )\n",
    "    list_patients.append(new_patient)\n",
    "#make the dataset\n",
    "dataset = pydmed.utils.data.Dataset(\"dataset_sample3Heatmap\", list_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms_onsmallchunkcollection =\\\n",
    "    torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToPILImage(),\\\n",
    "        torchvision.transforms.ToTensor(),\\\n",
    "        torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\\\n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "tfms_oncolate = torchvision.transforms.ToTensor()\n",
    "const_global_info = {\n",
    "    \"attention_levelidx\":1,\n",
    "    \"num_bigchunkloaders\":5,\n",
    "    \"maxlength_queue_smallchunk\":np.inf,\n",
    "    \"maxlength_queue_lightdl\":np.inf,\n",
    "    \"interval_resched\": 2,\n",
    "    \"core-assignment\":{\n",
    "                \"lightdl\":None,\n",
    "                \"smallchunkloaders\":None,\n",
    "                \"bigchunkloaders\":None\n",
    "              }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_forheatmap = pydmed.extensions.wsi.SlidingWindowDL(\n",
    "          intorfunc_opslevel = 1,\n",
    "          kernel_size = kernel_size,\n",
    "          stride = kernel_size,\n",
    "          mininterval_loadnewbigchunk = 15,\n",
    "          dataset = dataset,\\\n",
    "          type_bigchunkloader=pydmed.extensions.wsi.SlidingWindowBigChunkLoader,\\\n",
    "          type_smallchunkcollector=pydmed.extensions.wsi.SlidingWindowSmallChunkCollector,\\\n",
    "          const_global_info=const_global_info,\\\n",
    "          batch_size=1,\\\n",
    "          tfms_onsmallchunkcollection=tfms_onsmallchunkcollection,\\\n",
    "          tfms = tfms_oncolate,\n",
    "          flag_grabqueue_onunsched = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydmed.streamcollector\n",
    "from pydmed.streamcollector import *\n",
    "\n",
    "class HeatmapStreamCollector(StreamCollector):\n",
    "    def __init__(self, module_pipeline, device, *args, **kwargs):\n",
    "        #grab privates\n",
    "        self.module_pipeline = module_pipeline\n",
    "        self.device = device\n",
    "        #make other initial operations\n",
    "        self.module_pipeline.to(device)\n",
    "        self.module_pipeline.eval()\n",
    "        self.num_calls_to_getflagfinished = 0\n",
    "        super(HeatmapStreamCollector, self).__init__(*args, **kwargs)\n",
    "        \n",
    "        \n",
    "    @abstractmethod\n",
    "    def process_pieceofstream(self, retval_collatefunc):\n",
    "        x, list_patients, list_smallchunks = retval_collatefunc\n",
    "        with torch.no_grad():\n",
    "            netout = \\\n",
    "                self.module_pipeline(x.to(self.device))#[32x1x7x7]\n",
    "            list_processedpiece = []\n",
    "            for n in range(netout.shape[0]):\n",
    "                tensor_piecen = netout[n,0,:,:].unsqueeze(0)\n",
    "                str_piecen = pydmed.extensions.wsi.Tensor3DtoPdmcsvrow(\n",
    "                                tensor_piecen.detach().cpu().numpy(), list_smallchunks[n]\n",
    "                            )\n",
    "                list_processedpiece.append(\n",
    "                                   ProcessedPiece(\n",
    "                                      data = str_piecen,\\\n",
    "                                      source_smallchunk = list_smallchunks[n]\n",
    "                                    )\n",
    "                                 )\n",
    "        return list_processedpiece\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_flag_finishcollecting(self):\n",
    "        self.num_calls_to_getflagfinished += 1\n",
    "        is_dl_running = self.lightdl.is_dl_running()\n",
    "        if((is_dl_running==False) and (self.lightdl.queue_lightdl.qsize()==0)):\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statcollector = HeatmapStreamCollector(\n",
    "                module_pipeline=model,\n",
    "                device = device,\n",
    "                lightdl = dl_forheatmap,\n",
    "                str_collectortype = \"stream_to_file\",\n",
    "                flag_visualizestats= False,\n",
    "                kwargs_streamwriter = {\n",
    "                    \"rootpath\": \"./Output/GeneratedHeatmaps/\",\n",
    "                    \"fname_tosave\":None, \n",
    "                    \"waiting_time_before_flush\":3\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "statcollector.start_collecting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#make the default raster to WSI\n",
    "default_wsitoraster = pydmed.extensions.wsi.DefaultWSIxyWHvaltoRasterPoints()\n",
    "\n",
    "list_paddedregions = []\n",
    "for patient in dataset.list_patients:\n",
    "    print(\"idx_patient = {}\".format(patient.int_uniqueid))\n",
    "    fname_pdmcsv = \"Output/GeneratedHeatmaps/patient_{}.csv\".format(\n",
    "                        patient.int_uniqueid\n",
    "                     )\n",
    "    np_heatmap = pydmed.extensions.wsi.pdmcsvtoarray(\n",
    "                        fname_pdmcsv,\n",
    "                        default_wsitoraster.func_WSIxyWHval_to_rasterpoints,\n",
    "                        scale_upsampleraster = 1.0\n",
    "                    )\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(np_heatmap[:,:,0], cmap=\"jet\")\n",
    "    plt.colorbar()\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\n",
    "            \"Output/FromNdarraytoImage/patient_{}.png\".format(patient.int_uniqueid),\n",
    "             dpi=100, pad_inches=0, bbox_inches=\"tight\"\n",
    "            )\n",
    "    plt.show()\n",
    "    \n",
    "    np.save(\n",
    "        \"Output/FromNdarraytoImage/patient_{}\".format(patient.int_uniqueid),\n",
    "         np_heatmap\n",
    "      )\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
