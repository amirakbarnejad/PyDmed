{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import copy\n",
    "from abc import ABC, abstractmethod\n",
    "import math\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import PIL\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import threshold_otsu\n",
    "import torchvision\n",
    "import torchvision.models as torchmodels\n",
    "import torch.nn.functional as F\n",
    "import openslide\n",
    "import torch.utils.data\n",
    "\n",
    "list_pathstoadd = [\"../../\"]\n",
    "for path in list_pathstoadd:\n",
    "    if(path not in sys.path):\n",
    "        sys.path.append(path)\n",
    "import pydmed\n",
    "from pydmed.utils.data import *\n",
    "import pydmed.lightdl\n",
    "from pydmed.lightdl import *\n",
    "import pydmed.extensions.wsi\n",
    "import pydmed.streamcollector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#settings ====\n",
    "kernel_size = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the model ====\n",
    "module_resnet = torchvision.models.resnet50()\n",
    "list_modules = list(module_resnet.children())[0:-2]\n",
    "model = torch.nn.Sequential(*list_modules)\n",
    "\n",
    "def func_setpaddingmodes_for_conv2dlayers(module_input, str_paddingmode):\n",
    "    '''\n",
    "    Sets the padding mode of all conv2d modules, either on imediate children or non-imediate children.\n",
    "    '''\n",
    "    #get num_children\n",
    "    num_children = 0\n",
    "    for child in module_input.children():\n",
    "        num_children += 1\n",
    "    \n",
    "    #base case, the module has no children ====\n",
    "    if(num_children == 0):\n",
    "        if(isinstance(module_input, torch.nn.Conv2d)):\n",
    "            module_input.padding_mode = str_paddingmode\n",
    "        return module_input\n",
    "        \n",
    "    #non-base case, loop over children ====\n",
    "    for child in module_input.children():\n",
    "        func_setpaddingmodes_for_conv2dlayers(child, str_paddingmode)\n",
    "    return module_input\n",
    "\n",
    "model = func_setpaddingmodes_for_conv2dlayers(model, \"reflect\") #set paddingmode to \"reflect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dataset ===================\n",
    "rootdir = \"../../NonGit/Data/Sample3Heatmap/\"\n",
    "list_relativedirs = [\"1.tif\", \"2.tif\", \"3.tif\", \"4.tif\", \"5.tif\",\\\n",
    "                     \"6.tif\", \"7.tif\", \"8.tif\", \"9.tif\", \"10.tif\"]\n",
    "list_relativedirs.sort()\n",
    "#make a list of patients\n",
    "list_patients = []\n",
    "for fname in list_relativedirs:\n",
    "    new_patient = Patient(\\\n",
    "            int_uniqueid = list_relativedirs.index(fname),\n",
    "            dict_records = {\n",
    "                \"H&E\":Record(rootdir, fname, {\"resolution\":\"40x\"}),\n",
    "                \"somelabel\": np.random.randint(0,4)\n",
    "             }\n",
    "         )\n",
    "    list_patients.append(new_patient)\n",
    "#make the dataset\n",
    "dataset = pydmed.utils.data.Dataset(\"dataset_sample3Heatmap\", list_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_patient_to_fnameimage(patient_input):\n",
    "    fname_wsi = os.path.join(\n",
    "            patient_input.dict_records[\"H&E\"].rootdir,\n",
    "            patient_input.dict_records[\"H&E\"].relativedir\n",
    "          )\n",
    "    return fname_wsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms_onsmallchunkcollection =\\\n",
    "    torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToPILImage(),\\\n",
    "        torchvision.transforms.ToTensor(),\\\n",
    "        torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\\\n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "tfms_oncolate = torchvision.transforms.ToTensor()\n",
    "const_global_info = {\n",
    "    \"attention_levelidx\":1,\n",
    "    \"num_bigchunkloaders\":5,\n",
    "    \"maxlength_queue_smallchunk\":np.inf,\n",
    "    \"maxlength_queue_lightdl\":np.inf,\n",
    "    \"interval_resched\": 2,\n",
    "    \"core-assignment\":{\n",
    "                \"lightdl\":None,\n",
    "                \"smallchunkloaders\":None,\n",
    "                \"bigchunkloaders\":None\n",
    "              }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_forheatmap = pydmed.extensions.wsi.SlidingWindowDL(\n",
    "          intorfunc_opslevel = 1,\n",
    "          kernel_size = kernel_size,\n",
    "          func_patient_to_fnameimage = func_patient_to_fnameimage,\n",
    "          stride = kernel_size,\n",
    "          mininterval_loadnewbigchunk = 15,\n",
    "          dataset = dataset,\\\n",
    "          type_bigchunkloader=pydmed.extensions.wsi.SlidingWindowBigChunkLoader,\\\n",
    "          type_smallchunkcollector=pydmed.extensions.wsi.SlidingWindowSmallChunkCollector,\\\n",
    "          const_global_info=const_global_info,\\\n",
    "          batch_size=1,\\\n",
    "          tfms_onsmallchunkcollection=tfms_onsmallchunkcollection,\\\n",
    "          tfms = tfms_oncolate,\n",
    "          flag_grabqueue_onunsched = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydmed.streamcollector\n",
    "from pydmed.streamcollector import *\n",
    "\n",
    "class HeatmapStreamCollector(StreamCollector):\n",
    "    def __init__(self, module_pipeline, device, *args, **kwargs):\n",
    "        #grab privates\n",
    "        self.module_pipeline = module_pipeline\n",
    "        self.device = device\n",
    "        #make other initial operations\n",
    "        self.module_pipeline.to(device)\n",
    "        self.module_pipeline.eval()\n",
    "        self.num_calls_to_getflagfinished = 0\n",
    "        super(HeatmapStreamCollector, self).__init__(*args, **kwargs)\n",
    "        \n",
    "        \n",
    "    @abstractmethod\n",
    "    def process_pieceofstream(self, retval_collatefunc):\n",
    "        x, list_patients, list_smallchunks = retval_collatefunc\n",
    "        with torch.no_grad():\n",
    "            netout = \\\n",
    "                self.module_pipeline(x.to(self.device))#[32x1x7x7]\n",
    "            list_processedpiece = []\n",
    "            for n in range(netout.shape[0]):\n",
    "                stat_n = pydmed.extensions.wsi.Tensor3DtoPdmcsvrow(\n",
    "                                netout[n,0,:,:].unsqueeze(0), list_smallchunks[n]\n",
    "                            )\n",
    "                list_processedpiece.append(\n",
    "                                   ProcessedPiece(\n",
    "                                      data = stat_n,\\\n",
    "                                      source_smallchunk = list_smallchunks[n]\n",
    "                                    )\n",
    "                                 )\n",
    "        return list_processedpiece\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_flag_finishcollecting(self):\n",
    "        self.num_calls_to_getflagfinished += 1\n",
    "        is_dl_running = self.lightdl.is_dl_running()\n",
    "        if((is_dl_running==False) and (self.lightdl.queue_lightdl.qsize()==0)):\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statcollector = HeatmapStreamCollector(\n",
    "                module_pipeline=model,\n",
    "                device = device,\n",
    "                lightdl = dl_forheatmap,\n",
    "                str_collectortype = \"stream_to_file\",\n",
    "                flag_visualizestats= False,\n",
    "                kwargs_streamwriter = {\n",
    "                    \"rootpath\": \"NonGit/GeneratedHeatmaps/\",\n",
    "                    \"fname_tosave\":None, \n",
    "                    \"waiting_time_before_flush\":3\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "statcollector.start_collecting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:delete transfered to pydmed\n",
    "def Tensor3DtoPdmcsvrow(np_input, smalchunk_input):\n",
    "    '''\n",
    "    Converts a Tensor of shape [C x H x W] to pdmcsv format.\n",
    "    Inputs.\n",
    "        - np_input: a numpy array of shape [CxHxW].\n",
    "        - smallchunk_input: an instnace of SmallChunk,\n",
    "                            the smallchunk that that the tensor corresponds to.\n",
    "    '''\n",
    "    chw = list(np_input.shape)\n",
    "    str_toret = str([\n",
    "        smalchunk_input.dict_info_of_bigchunk[\"y\"],\\\n",
    "        smalchunk_input.dict_info_of_smallchunk[\"x\"],\\\n",
    "        smalchunk_input.dict_info_of_bigchunk[\"H\"],\\\n",
    "        smalchunk_input.dict_info_of_bigchunk[\"W\"],\\\n",
    "        smalchunk_input.dict_info_of_smallchunk[\"patch_levelidx\"],\\\n",
    "        smalchunk_input.dict_info_of_smallchunk[\"kernel_size\"],\n",
    "        smalchunk_input.dict_info_of_bigchunk[\"downsample_of_patchlevel\"],\n",
    "        chw[0], chw[1], chw[2]\n",
    "       ])[1:-1]+ \",\" +\\\n",
    "       str(np_input.flatten().tolist())[1:-1] + \"\\n\"\n",
    "    return str_toret\n",
    "    \n",
    "\n",
    "\n",
    "def pdmcsvtoarray(fname_pdmcsv, func_WSIxyWHval_to_rasterpoints, scale_upsampleraster=1.0):\n",
    "    '''\n",
    "    Converts a pdmcsv file to an array.\n",
    "    Inputs.\n",
    "        - fname_pdmcsv: a string, the path-filename to the pdmcsv file.\n",
    "        - outputsize: a float, the scale of output. The default value is 1.0 meaning the output\n",
    "            array is not scaled.\n",
    "        - func_WSIxyval_to_rasterpoints: a function.\n",
    "            - Inputs.\n",
    "                x: a number, as in one line of the pdm.csv file.\n",
    "                y: a number, as in one line of the pdm.csv file.\n",
    "                W: an integer.\n",
    "                H: an integer.\n",
    "                val: list of values.\n",
    "            -Outputs.\n",
    "                - list_x_onraster:\n",
    "                - list_y_onraster:\n",
    "                - list_val_onraster:\n",
    "    '''\n",
    "    #read the file line-by-line =====\n",
    "    file_pdmcsv = open(fname_pdmcsv, 'r')\n",
    "    count_line = 0\n",
    "    dict_raster = {}\n",
    "    while True:\n",
    "        count_line += 1\n",
    "        line = file_pdmcsv.readline() \n",
    "        \n",
    "        if not line: \n",
    "                break\n",
    "              \n",
    "        list_numbers = line.split(\",\")\n",
    "        for idx, u in enumerate(list_numbers):\n",
    "            if(isinstance(list_numbers[idx], str)):\n",
    "                if(\"None\" in list_numbers[idx]):\n",
    "                    list_numbers[idx] = np.nan\n",
    "        list_numbers = [float(u) for u in list_numbers]\n",
    "        \n",
    "        if(count_line == 1):\n",
    "            H, W = list_numbers[2], list_numbers[3]\n",
    "            H, W = int(H), int(W)\n",
    "        \n",
    "        #order: y,x,H,W,....  \n",
    "        y, x = list_numbers[0], list_numbers[1]\n",
    "        patch_levelidx = list_numbers[4]\n",
    "        kernel_size = list_numbers[5]\n",
    "        downsample_of_patchlevel = list_numbers[6]\n",
    "        c = int(list_numbers[7])\n",
    "        h = int(list_numbers[8])\n",
    "        w = int(list_numbers[9])\n",
    "        val = list_numbers[10:] #np.mean(np.array([list_numbers[4:]]))\n",
    "        \n",
    "        #convert the points to raster space using the function\n",
    "        list_x_onraster, list_y_onraster, val = func_WSIxyWHval_to_rasterpoints(\n",
    "                                            x, y, W, H,\n",
    "                                            patch_levelidx,\n",
    "                                            kernel_size,\n",
    "                                            downsample_of_patchlevel,\n",
    "                                            c, h, w, val\n",
    "                                        )\n",
    "        #np_x_onraster, np_y_onraster = np.array(list_x_onraster), np.array(list_y_onraster)\n",
    "        for idx_rasterpoint in range(len(list_x_onraster)):\n",
    "            dict_raster[\"({},{})\".format(\n",
    "                     math.floor(list_x_onraster[idx_rasterpoint]),\n",
    "                     math.floor(list_y_onraster[idx_rasterpoint])\n",
    "                    )\n",
    "                ] = val[idx_rasterpoint]\n",
    "    \n",
    "    #convert dict_raster to np.ndarray =====\n",
    "    list_allrasterx, list_allrastery = [], []\n",
    "    for u in dict_raster.keys():\n",
    "        x, y = u[1:-1].split(',')\n",
    "        x, y = float(x), float(y) \n",
    "        if(scale_upsampleraster > 1.0):\n",
    "            x, y = scale_upsampleraster*x, scale_upsampleraster*y\n",
    "        x, y = math.floor(x), math.floor(y)\n",
    "        list_allrasterx.append(x); list_allrastery.append(y)\n",
    "    list_allrasterx = list(set(list_allrasterx))\n",
    "    list_allrastery = list(set(list_allrastery))\n",
    "    list_allrasterx.sort(); list_allrastery.sort()\n",
    "    max_x, max_y = np.max(list_allrasterx), np.max(list_allrastery)\n",
    "    output_raster = np.zeros((len(list_allrastery), len(list_allrasterx), c))\n",
    "    num_totalloops = len(list(dict_raster.keys()))\n",
    "    count = 0\n",
    "    for u in dict_raster.keys():\n",
    "        count += 1\n",
    "        if((count%10000) == 0):\n",
    "            print(\"    >>>>>> Interpolation in progress: point {} out of {}. Please wait .... .\".format(count, num_totalloops), end=\"\\r\")\n",
    "        x,y = u[1:-1].split(',')\n",
    "        x, y = float(x), float(y)\n",
    "        if(scale_upsampleraster > 1.0):\n",
    "            x, y = scale_upsampleraster*x, scale_upsampleraster*y\n",
    "        x, y = math.floor(x), math.floor(y)\n",
    "        output_raster[list_allrastery.index(y), list_allrasterx.index(x),:] = dict_raster[u]\n",
    "    #fill-in the zeros if scale_upsample>1.0\n",
    "    if(scale_upsampleraster > 1.0):\n",
    "        list_output_scaled = []\n",
    "        for count_c in range(c):\n",
    "            f = interp2d(\n",
    "                np.array(list_allrasterx),\n",
    "                np.array(list_allrastery),\n",
    "                output_raster[:,:,count_c], kind='cubic'\n",
    "            )\n",
    "            output_raster_scaled_forchannel = f(\n",
    "                   np.array([j for j in range(max_x)]),\n",
    "                   np.array([i for i in range(max_y)])\n",
    "                 )\n",
    "            list_output_scaled.append(output_raster_scaled_forchannel)\n",
    "        return np.stack(list_output_scaled, 2)\n",
    "    return output_raster\n",
    "\n",
    "\n",
    "class DefaultWSIxyWHvaltoRasterPoints:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def func_WSIxyWHval_to_rasterpoints(\n",
    "                self, x, y, W, H,\n",
    "                patch_levelidx, kernel_size,\n",
    "                downsample_of_patchlevel,\n",
    "                c, h, w, val):\n",
    "        assert(isinstance(val, list))\n",
    "        assert((c*h*w)== len(val))\n",
    "        np_val = np.reshape(val, [c,h,w])\n",
    "        \n",
    "        size_blockonraster = h #np.sqrt(len(val))\n",
    "        scale_wsi_to_raster = kernel_size/size_blockonraster\n",
    "        x_onraster = (x+0.0)/scale_wsi_to_raster\n",
    "        y_onraster = (y+0.0)/scale_wsi_to_raster\n",
    "        #make list_x_onraster and list_y_onraster ======\n",
    "        np_x_onraster = np.array([[j for j in range(int(size_blockonraster))]\\\n",
    "                             for i in range(int(size_blockonraster))]).flatten()+x_onraster\n",
    "        np_y_onraster = np.array([[i for j in range(int(size_blockonraster))]\\\n",
    "                             for i in range(int(size_blockonraster))]).flatten()+y_onraster\n",
    "        list_x_onraster = np_x_onraster.tolist()\n",
    "        list_y_onraster = np_y_onraster.tolist()\n",
    "        toret_val = []\n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                toret_val.append(np_val[:,i,j])\n",
    "        return list_x_onraster, list_y_onraster, toret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#make the default raster to WSI\n",
    "default_wsitoraster = DefaultWSIxyWHvaltoRasterPoints()\n",
    "\n",
    "list_paddedregions = []\n",
    "for patient in dataset.list_patients:\n",
    "    print(\"idx_patient = {}\".format(patient.int_uniqueid))\n",
    "    fname_pdmcsv = \"NonGit/GeneratedHeatmaps/patient_{}.csv\".format(\n",
    "                        patient.int_uniqueid\n",
    "                     )\n",
    "    np_heatmap = pdmcsvtoarray(\n",
    "                        fname_pdmcsv,\n",
    "                        default_wsitoraster.func_WSIxyWHval_to_rasterpoints,\n",
    "                        scale_upsampleraster = 1.0\n",
    "                    )\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(np_heatmap[:,:,0], cmap=\"jet\")\n",
    "    plt.colorbar()\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\n",
    "            \"NonGit/FromNdarraytoImage/patient_{}.png\".format(patient.int_uniqueid),\n",
    "             dpi=100, pad_inches=0, bbox_inches=\"tight\"\n",
    "            )\n",
    "    plt.show()\n",
    "    \n",
    "    np.save(\n",
    "        \"NonGit/FromNdarraytoImage/patient_{}\".format(patient.int_uniqueid),\n",
    "         np_heatmap\n",
    "      )\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
