{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "from abc import ABC, abstractmethod\n",
    "import math\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import PIL\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import threshold_otsu\n",
    "import torchvision\n",
    "import torchvision.models as torchmodels\n",
    "import torch.nn.functional as F\n",
    "import openslide\n",
    "import torch.utils.data\n",
    "\n",
    "list_pathstoadd = [\"../\"]\n",
    "for path in list_pathstoadd:\n",
    "    if(path not in sys.path):\n",
    "        sys.path.append(path)\n",
    "import pydmed\n",
    "from pydmed.utils.data import *\n",
    "import pydmed.lightdl\n",
    "from pydmed.lightdl import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dataset (section 1 of tutorial) ===================\n",
    "rootdir = \"../NonGit/Data/\"\n",
    "list_relativedirs = [\"1.svs\", \"2.svs\", \"3.svs\", \"4.svs\", \"5.svs\"]\n",
    "list_relativedirs.sort()\n",
    "#make a list of patients\n",
    "list_patients = []\n",
    "for fname in list_relativedirs:\n",
    "    new_patient = Patient(\\\n",
    "                    int_uniqueid = list_relativedirs.index(fname),\n",
    "                    dict_records = \\\n",
    "                      {\"H&E\":Record(rootdir, fname, {\"resolution\":\"40x\"}),\\\n",
    "                       \"HER2-status\": np.random.randint(0,4)}) #TODO:set real labels\n",
    "    list_patients.append(new_patient)\n",
    "#make the dataset\n",
    "dataset = pydmed.utils.data.Dataset(\"myHER2dataset\", list_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def otsu_getpoint_from_foreground(fname_wsi):\n",
    "    #settings =======\n",
    "    scale_thumbnail =  0.01\n",
    "    width_targetpatch = 5000 \n",
    "    #extract the foreground =========================\n",
    "    osimage = openslide.OpenSlide(fname_wsi)\n",
    "    W, H = osimage.dimensions\n",
    "    size_thumbnail = (int(scale_thumbnail*W), int(scale_thumbnail*H))\n",
    "    pil_thumbnail = osimage.get_thumbnail(size_thumbnail)\n",
    "    np_thumbnail = np.array(pil_thumbnail)\n",
    "    np_thumbnail = np_thumbnail[:,:,0:3]\n",
    "    np_thumbnail = rgb2gray(np_thumbnail)\n",
    "    thresh = threshold_otsu(np_thumbnail)\n",
    "    background = (np_thumbnail > thresh) + 0.0\n",
    "    foreground = 1.0 - background\n",
    "    #apply the padding on foreground\n",
    "    w_padding_of_thumbnail = int(width_targetpatch * scale_thumbnail)\n",
    "    foreground[0:w_padding_of_thumbnail, :] = 0\n",
    "    foreground[-w_padding_of_thumbnail::, :] = 0\n",
    "    foreground[: , 0:w_padding_of_thumbnail] = 0\n",
    "    foreground[: , -w_padding_of_thumbnail::] = 0\n",
    "    #select a random point =========================\n",
    "    one_indices = np.where(foreground==1.0)\n",
    "    i_oneindices, j_oneindices = one_indices[0].tolist(), one_indices[1].tolist()\n",
    "    n = random.choice(range(len(i_oneindices)))\n",
    "    i_selected, j_selected = i_oneindices[n], j_oneindices[n]\n",
    "    assert(foreground[i_selected, j_selected] == 1)\n",
    "    i_selected_realscale, j_selected_realscale =\\\n",
    "        int(i_selected/scale_thumbnail), int(j_selected/scale_thumbnail)\n",
    "    x, y = j_selected_realscale, i_selected_realscale\n",
    "    return x,y \n",
    "    \n",
    "class WSIRandomBigchunkLoader(BigChunkLoader):\n",
    "    @abstractmethod\n",
    "    def extract_bigchunk(self, last_message_fromroot):\n",
    "        '''\n",
    "        Extract and return a bigchunk. \n",
    "        Please note that in this function you have access to\n",
    "        self.patient and self.const_global_info.\n",
    "        '''\n",
    "        self.log(\"in time {} a BigChunk loaded.\\n\".format(time.time()))\n",
    "        list_bigchunks = []\n",
    "        for idx_bigpatch in range(5):\n",
    "            #settings ==== \n",
    "            flag_use_otsu = True\n",
    "            #===\n",
    "            wsi = self.patient.dict_records[\"H&E\"]\n",
    "            fname_wsi = wsi.rootdir + wsi.relativedir\n",
    "            osimage = openslide.OpenSlide(fname_wsi)\n",
    "            w, h = 1000, 1000\n",
    "            W, H = osimage.dimensions\n",
    "            if(flag_use_otsu == True):\n",
    "                rand_x, rand_y = otsu_getpoint_from_foreground(fname_wsi)\n",
    "                rand_x, rand_y = int(rand_x-(w*0.5)), int(rand_y-(h*0.5))\n",
    "            else:\n",
    "                rand_x, rand_y = np.random.randint(0, W-w), np.random.randint(0, H-h)\n",
    "            pil_bigchunk = osimage.read_region([rand_x, rand_y], 0, [w,h])\n",
    "            np_bigchunk = np.array(pil_bigchunk)[:,:,0:3]\n",
    "            bigchunk = BigChunk(data=np_bigchunk,\\\n",
    "                                 dict_info_of_bigchunk={\"x\":rand_x, \"y\":rand_y},\\\n",
    "                                 patient=self.patient)\n",
    "            list_bigchunks.append(bigchunk)\n",
    "        return list_bigchunks\n",
    "\n",
    "class WSIRandomSmallchunkCollector(SmallChunkCollector):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        #grab privates\n",
    "        self.tfms_onsmallchunkcollection =\\\n",
    "            torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToPILImage(),\\\n",
    "            torchvision.transforms.Resize((224,224)),\\\n",
    "            torchvision.transforms.ColorJitter(brightness=0,\\\n",
    "                                     contrast=0,\\\n",
    "                                     saturation=0.5,\\\n",
    "                                     hue=[-0.1, 0.1]),\\\n",
    "            torchvision.transforms.ToTensor(),\\\n",
    "            torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\\\n",
    "                                   std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        super(WSIRandomSmallchunkCollector, self).__init__(*args, **kwargs)\n",
    "    \n",
    "    \n",
    "    @abstractmethod     \n",
    "    def extract_smallchunk(self, call_count, list_bigchunks, last_message_fromroot):\n",
    "        '''\n",
    "        Extract and return a smallchunk. Please note that in this function you have access to \n",
    "        self.bigchunk, self.patient, self.const_global_info.\n",
    "        Inputs:\n",
    "            - list_bigchunks: the list of extracted bigchunks.\n",
    "            - Other arguemtns are not needed in this sample notebook.\n",
    "        '''\n",
    "        bigchunk = random.choice(list_bigchunks)\n",
    "        W, H = bigchunk.data.shape[1], bigchunk.data.shape[0]\n",
    "        w, h = 224, 224\n",
    "        rand_x, rand_y = np.random.randint(0, W-w), np.random.randint(0, H-h)\n",
    "        np_smallchunk = bigchunk.data[rand_y:rand_y+h, rand_x:rand_x+w, :]\n",
    "        #apply the transformation ===========\n",
    "        if(self.tfms_onsmallchunkcollection != None):\n",
    "            toret = self.tfms_onsmallchunkcollection(np_smallchunk)\n",
    "            toret = toret.cpu().detach().numpy() #[3 x 224 x 224]\n",
    "            toret = np.transpose(toret, [1,2,0]) #[224 x 224 x 3]\n",
    "        else:\n",
    "            toret = np_smallchunk\n",
    "        #wrap in SmallChunk\n",
    "        smallchunk = SmallChunk(data=toret,\\\n",
    "                                dict_info_of_smallchunk={\"x\":rand_x, \"y\":rand_y},\\\n",
    "                                dict_info_of_bigchunk = bigchunk.dict_info_of_bigchunk,\\\n",
    "                                patient=bigchunk.patient)\n",
    "        return smallchunk        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dataloader ================== \n",
    "tfms = torchvision.transforms.ToTensor()\n",
    "const_global_info = {\n",
    "    \"num_bigchunkloaders\":5,\n",
    "    \"maxlength_queue_smallchunk\":100,\n",
    "    \"maxlength_queue_lightdl\":10000,\n",
    "    \"interval_resched\": 10,\n",
    "    \"core-assignment\":{\"lightdl\":None,\n",
    "                       \"smallchunkloaders\":None,\n",
    "                       \"bigchunkloaders\":None}\n",
    "}\n",
    "dataloader = LightDL(dataset=dataset,\\\n",
    "                     type_bigchunkloader=WSIRandomBigchunkLoader,\\\n",
    "                     type_smallchunkcollector=WSIRandomSmallchunkCollector,\\\n",
    "                     const_global_info=const_global_info,\\\n",
    "                     batch_size=10, tfms=tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#build the model and optimizer====================\n",
    "model = torchmodels.resnet18(pretrained=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model.to(device)\n",
    "model.train()\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loading initial bigchunks (please wait)\n",
      " bigchunk 0 from 5\n",
      "\n",
      " bigchunk 1 from 5\n",
      "\n",
      " bigchunk 2 from 5\n",
      "\n",
      " bigchunk 3 from 5\n",
      "\n",
      " bigchunk 4 from 5\n",
      "\n",
      "The initial loading of bigchunks took 22.76441478729248 seconds.\n",
      "*************  batchcount = 10 ************\n",
      "*************  batchcount = 20 ************\n",
      "*************  batchcount = 30 ************\n",
      "*************  batchcount = 40 ************\n",
      "*************  batchcount = 50 ************\n",
      "*************  batchcount = 60 ************\n",
      "*************  batchcount = 70 ************\n",
      "*************  batchcount = 80 ************\n",
      "*************  batchcount = 90 ************\n",
      "*************  batchcount = 100 ************\n",
      "*************  batchcount = 110 ************\n",
      "*************  batchcount = 120 ************\n",
      "*************  batchcount = 130 ************\n",
      "*************  batchcount = 140 ************\n",
      "*************  batchcount = 150 ************\n",
      "*************  batchcount = 160 ************\n",
      "*************  batchcount = 170 ************\n",
      "*************  batchcount = 180 ************\n",
      "*************  batchcount = 190 ************\n",
      "*************  batchcount = 200 ************\n"
     ]
    }
   ],
   "source": [
    "#train the model ============================\n",
    "dataloader.start()\n",
    "time.sleep(20)\n",
    "tstart = time.time()\n",
    "batchcount = 0\n",
    "while True:\n",
    "    x, list_patients, list_smallchunks = dataloader.get()\n",
    "    y = torch.from_numpy(np.array([patient.dict_records['HER2-status']\n",
    "                                   for patient in list_patients])).to(device)\n",
    "    batchcount += 1\n",
    "    optimizer.zero_grad()\n",
    "    netout = model(x.to(device))\n",
    "    loss = criterion(netout, y)\n",
    "    loss.backward()\n",
    "    if((batchcount%10)==0):\n",
    "        print(\"*************  batchcount = {} ************\".format(batchcount))\n",
    "    if(batchcount>200): \n",
    "        dataloader.pause_loading()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
